import os
import pandas as pd
import torch
from torch.utils.data import Dataset
from PIL import Image
from io import BytesIO
from typing import Optional, Callable, Union
from pathlib import Path
import glob


class PredictionGeoDataset(Dataset):
    """
    PyTorch Dataset for loading prediction results from parquet files generated by generate.py.
    Supports both single parquet files and sharded parquet files.
    
    The parquet files contain:
        - 'image_bytes': binary image data (JPEG format)
        - 'true_lat': true latitude coordinate
        - 'true_lon': true longitude coordinate
        - 'pred_lat': predicted latitude coordinate
        - 'pred_lon': predicted longitude coordinate
    """
    
    def __init__(
        self,
        parquet_path: Union[str, Path],
        transform: Optional[Callable] = None,
        max_samples: Optional[int] = None
    ):
        """
        Args:
            parquet_path: Path to parquet file/directory containing prediction results.
                         Can be a single file or a directory containing sharded files (part_*.parquet)
            transform: Optional torchvision transform to apply to images
            max_samples: Optional limit on number of samples to load (useful for debugging)
        """
        self.parquet_path = Path(parquet_path)
        self.transform = transform
        
        # Determine if we have a single file or sharded files
        if self.parquet_path.is_file():
            # Single parquet file
            parquet_files = [self.parquet_path]
        elif self.parquet_path.is_dir():
            # Directory with sharded files
            parquet_files = sorted(self.parquet_path.glob("part_*.parquet"))
            if not parquet_files:
                raise FileNotFoundError(f"No parquet files found in directory: {self.parquet_path}")
        else:
            raise FileNotFoundError(f"Parquet path not found: {self.parquet_path}")
        
        # Load all parquet files
        print(f"Loading prediction data from {len(parquet_files)} parquet file(s)")
        dfs = []
        for file_path in parquet_files:
            print(f"Loading {file_path}")
            df = pd.read_parquet(file_path)
            dfs.append(df)
        
        # Concatenate all dataframes
        self.df = pd.concat(dfs, ignore_index=True)
        
        # Apply max_samples limit if specified
        if max_samples is not None:
            self.df = self.df.head(max_samples)
        
        print(f"Loaded {len(self.df)} prediction samples from {len(parquet_files)} file(s)")
        
        # Verify required columns exist
        required_columns = ['image_bytes', 'true_lat', 'true_lon', 'pred_lat', 'pred_lon']
        missing_columns = [col for col in required_columns if col not in self.df.columns]
        if missing_columns:
            raise ValueError(f"Missing required columns in parquet file: {missing_columns}")
    
    def __len__(self) -> int:
        """Return the number of samples in the dataset."""
        return len(self.df)
    
    def __getitem__(self, idx: int) -> dict:
        """
        Get a single item from the dataset.
        
        Args:
            idx: Index of the sample to retrieve
            
        Returns:
            Dictionary containing:
                - 'image': transformed image tensor
                - 'true_lat': true latitude value (float)
                - 'true_lon': true longitude value (float)
                - 'pred_lat': predicted latitude value (float)
                - 'pred_lon': predicted longitude value (float)
                - 'idx': dataset index (int)
        """
        if idx < 0 or idx >= len(self):
            raise IndexError(f"Index {idx} out of range for dataset of size {len(self)}")
        
        # Get the row data
        row = self.df.iloc[idx]
        
        # Decode image from bytes
        image_bytes = row['image_bytes']
        if isinstance(image_bytes, str):
            image_bytes = image_bytes.encode('latin1')
        
        image = Image.open(BytesIO(image_bytes)).convert('RGB')
        
        # Apply transform if provided
        if self.transform:
            image = self.transform(image)
        
        return {
            'image': image,
            'true_lat': torch.tensor(float(row['true_lat'])),
            'true_lon': torch.tensor(float(row['true_lon'])),
            'pred_lat': torch.tensor(float(row['pred_lat'])),
            'pred_lon': torch.tensor(float(row['pred_lon'])),
            'idx': torch.tensor(idx)
        }
    
    def get_stats(self) -> dict:
        """
        Get statistics about the dataset.
        
        Returns:
            Dictionary containing dataset statistics
        """
        # Find all parquet files that were loaded
        if self.parquet_path.is_file():
            parquet_files = [str(self.parquet_path)]
        else:
            parquet_files = [str(f) for f in sorted(self.parquet_path.glob("part_*.parquet"))]
        
        return {
            'total_samples': len(self.df),
            'parquet_path': str(self.parquet_path),
            'parquet_files': parquet_files,
            'num_shards': len(parquet_files),
            'columns': list(self.df.columns),
            'lat_range': (self.df['true_lat'].min(), self.df['true_lat'].max()),
            'lon_range': (self.df['true_lon'].min(), self.df['true_lon'].max()),
            'pred_lat_range': (self.df['pred_lat'].min(), self.df['pred_lat'].max()),
            'pred_lon_range': (self.df['pred_lon'].min(), self.df['pred_lon'].max())
        }
