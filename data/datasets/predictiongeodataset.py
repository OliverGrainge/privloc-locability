import os
import pandas as pd
import torch
from torch.utils.data import Dataset
from PIL import Image
from io import BytesIO
from typing import Optional, Callable, Union, List
from pathlib import Path
import glob
from tqdm import tqdm 
from torchvision import transforms


class PredictionGeoDataset(Dataset):
    """
    PyTorch Dataset for loading prediction results from parquet files generated by generate.py.
    Supports both single parquet files and sharded parquet files.
    
    The parquet files contain:
        - 'image_bytes': binary image data (JPEG format)
        - 'true_lat': true latitude coordinate
        - 'true_lon': true longitude coordinate
        - 'pred_lat': predicted latitude coordinate
        - 'pred_lon': predicted longitude coordinate
        - 'embedding': image embedding (optional, if generated with embeddings=True)
    """
    
    def __init__(
        self,
        parquet_path: Union[str, Path],
        transform: Optional[Callable] = None,
        max_samples: Optional[int] = None
    ):
        """
        Args:
            parquet_path: Path to parquet file/directory containing prediction results.
                         Can be a single file or a directory containing sharded files (part_*.parquet)
            transform: Optional torchvision transform to apply to images
            max_samples: Optional limit on number of samples to load (useful for debugging)
        """
        self.parquet_path = Path(parquet_path)
        self.transform = transform if transform is not None else self._default_transform()
        self.max_samples = max_samples
        
        # Determine if we have a single file or sharded files
        if self.parquet_path.is_file():
            # Single parquet file
            self.parquet_files = [self.parquet_path]
        elif self.parquet_path.is_dir():
            # Directory with sharded files
            self.parquet_files = sorted(self.parquet_path.glob("part_*.parquet"))
            if not self.parquet_files:
                raise FileNotFoundError(f"No parquet files found in directory: {self.parquet_path}")
        else:
            raise FileNotFoundError(f"Parquet path not found: {self.parquet_path}")
        
        # Initialize lazy loading state
        self.current_file_idx = None
        self.current_df = None
        self.file_start_indices = []
        self.total_samples = 0
        
        # Prefetching state
        self.prefetch_next = True
        self.next_file_df = None
        self.next_file_idx = None
        
        # Embedding state
        self.has_embeddings = False
        
        # Calculate file start indices and total samples without loading data
        print(f"Scanning {len(self.parquet_files)} parquet file(s) for metadata")
        for i, file_path in enumerate(self.parquet_files):
            # Read just the metadata to get row count
            df_meta = pd.read_parquet(file_path, engine='pyarrow')
            file_rows = len(df_meta)
            self.file_start_indices.append(self.total_samples)
            self.total_samples += file_rows
            print(f"File {i + 1}/{len(self.parquet_files)}: {file_path} ({file_rows} rows)")
        
        # Apply max_samples limit if specified
        if self.max_samples is not None:
            self.total_samples = min(self.total_samples, self.max_samples)
        
        print(f"Total samples across all files: {self.total_samples}")
        
        # Verify required columns exist by checking the first file
        if self.parquet_files:
            sample_df = pd.read_parquet(self.parquet_files[0])
            required_columns = ['image_bytes', 'true_lat', 'true_lon', 'pred_lat', 'pred_lon']
            missing_columns = [col for col in required_columns if col not in sample_df.columns]
            if missing_columns:
                raise ValueError(f"Missing required columns in parquet file: {missing_columns}")
            
            # Check if embeddings are present
            if 'embedding' in sample_df.columns:
                self.has_embeddings = True
                print("Embeddings detected in parquet files")
            else:
                print("No embeddings found in parquet files")

    def _default_transform(self):
        return transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),
            transforms.CenterCrop(224),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def _load_file_if_needed(self, file_idx: int):
        """Load a parquet file if it's not currently loaded."""
        if self.current_file_idx != file_idx:
            # Check if we have prefetched data for this file
            if self.next_file_idx == file_idx and self.next_file_df is not None:
                print(f"Using prefetched Shard {file_idx + 1}/{len(self.parquet_files)}: {self.parquet_files[file_idx]}")
                self.current_df = self.next_file_df
                self.current_file_idx = file_idx
                self.next_file_df = None
                self.next_file_idx = None
            else:
                # Clear previous file from memory
                if self.current_file_idx is not None and self.current_df is not None:
                    del self.current_df
                    import gc
                    gc.collect()
                    # Clear CUDA cache if available
                    try:
                        import torch
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    except ImportError:
                        pass
                
                print(f"Loading Shard {file_idx + 1}/{len(self.parquet_files)}: {self.parquet_files[file_idx]}")
                self.current_df = pd.read_parquet(self.parquet_files[file_idx])
                self.current_file_idx = file_idx
            
            # Prefetch next file if available
            if self.prefetch_next and file_idx + 1 < len(self.parquet_files):
                self._prefetch_next_file(file_idx)
    
    def _prefetch_next_file(self, current_file_idx: int):
        """Prefetch the next file in background."""
        next_file_idx = current_file_idx + 1
        if next_file_idx < len(self.parquet_files) and self.next_file_idx != next_file_idx:
            try:
                print(f"Prefetching Shard {next_file_idx + 1}/{len(self.parquet_files)}: {self.parquet_files[next_file_idx]}")
                self.next_file_df = pd.read_parquet(self.parquet_files[next_file_idx])
                self.next_file_idx = next_file_idx
            except Exception as e:
                print(f"Failed to prefetch file {next_file_idx}: {e}")
                self.next_file_df = None
                self.next_file_idx = None
    
    def get_file_samples(self, file_idx: int) -> List[dict]:
        """
        Get all samples from a specific parquet file.
        This is more efficient than random access when you need all samples from a file.
        
        Args:
            file_idx: Index of the parquet file to load
            
        Returns:
            List of sample dictionaries
        """
        if file_idx < 0 or file_idx >= len(self.parquet_files):
            raise IndexError(f"File index {file_idx} out of range for {len(self.parquet_files)} files")
        
        # Load the file
        self._load_file_if_needed(file_idx)
        
        samples = []
        for i in range(len(self.current_df)):
            # Calculate global index
            global_idx = self.file_start_indices[file_idx] + i
            
            # Apply max_samples limit if specified
            if self.max_samples is not None and global_idx >= self.max_samples:
                break
                
            row = self.current_df.iloc[i]
            
            # Decode image from bytes
            image_bytes = row['image_bytes']
            if isinstance(image_bytes, str):
                image_bytes = image_bytes.encode('latin1')
            
            image = Image.open(BytesIO(image_bytes)).convert('RGB')
            
            # Apply transform if provided
            if self.transform:
                image = self.transform(image)
            
            sample = {
                'image': image,
                'true_lat': torch.tensor(float(row['true_lat'])),
                'true_lon': torch.tensor(float(row['true_lon'])),
                'pred_lat': torch.tensor(float(row['pred_lat'])),
                'pred_lon': torch.tensor(float(row['pred_lon'])),
                'idx': torch.tensor(global_idx)
            }
            
            # Add embedding if available
            if self.has_embeddings and 'embedding' in row:
                # Convert bytes back to numpy array
                import numpy as np
                embedding_bytes = row['embedding']
                if isinstance(embedding_bytes, bytes):
                    embedding = np.frombuffer(embedding_bytes, dtype=np.float32)
                    sample['embedding'] = torch.tensor(embedding)
            
            samples.append(sample)
        
        return samples
    
    def __len__(self) -> int:
        """Return the number of samples in the dataset."""
        return self.total_samples
    
    def __getitem__(self, idx: int) -> dict:
        """
        Get a single item from the dataset.
        
        Args:
            idx: Index of the sample to retrieve
            
        Returns:
            Dictionary containing:
                - 'image': transformed image tensor
                - 'true_lat': true latitude value (float)
                - 'true_lon': true longitude value (float)
                - 'pred_lat': predicted latitude value (float)
                - 'pred_lon': predicted longitude value (float)
                - 'idx': dataset index (int)
                - 'embedding': image embedding tensor (if available)
        """
        if idx < 0 or idx >= len(self):
            raise IndexError(f"Index {idx} out of range for dataset of size {len(self)}")
        
        # Apply max_samples limit if specified
        if self.max_samples is not None and idx >= self.max_samples:
            raise IndexError(f"Index {idx} exceeds max_samples limit of {self.max_samples}")
        
        # Find which file contains this index
        file_idx = 0
        for i, start_idx in enumerate(self.file_start_indices):
            if i + 1 < len(self.file_start_indices):
                next_start = self.file_start_indices[i + 1]
            else:
                next_start = self.total_samples
            
            if start_idx <= idx < next_start:
                file_idx = i
                break
        
        # Load the file if needed
        self._load_file_if_needed(file_idx)
        
        # Calculate the local index within the current file
        local_idx = idx - self.file_start_indices[file_idx]
        
        # Get the row data
        row = self.current_df.iloc[local_idx]
        
        # Decode image from bytes
        image_bytes = row['image_bytes']
        if isinstance(image_bytes, str):
            image_bytes = image_bytes.encode('latin1')
        
        image = Image.open(BytesIO(image_bytes)).convert('RGB')
        
        # Apply transform if provided
        if self.transform:
            image = self.transform(image)
        
        result = {
            'image': image,
            'true_lat': torch.tensor(float(row['true_lat'])),
            'true_lon': torch.tensor(float(row['true_lon'])),
            'pred_lat': torch.tensor(float(row['pred_lat'])),
            'pred_lon': torch.tensor(float(row['pred_lon'])),
            'idx': torch.tensor(idx)
        }
        
        # Add embedding if available
        if self.has_embeddings and 'embedding' in row:
            # Convert bytes back to numpy array
            import numpy as np
            embedding_bytes = row['embedding']
            if isinstance(embedding_bytes, bytes):
                embedding = np.frombuffer(embedding_bytes, dtype=np.float32)
                result['embedding'] = torch.tensor(embedding)
        
        return result
    
    def get_stats(self) -> dict:
        """
        Get statistics about the dataset.
        
        Returns:
            Dictionary containing dataset statistics
        """
        # Get file information
        parquet_files = [str(f) for f in self.parquet_files]
        
        # For coordinate ranges, we need to load all files and compute statistics
        # This is expensive but necessary for accurate stats
        print("Computing coordinate statistics across all files...")
        all_lats = []
        all_lons = []
        all_pred_lats = []
        all_pred_lons = []
        
        for file_path in self.parquet_files:
            df = pd.read_parquet(file_path)
            all_lats.extend(df['true_lat'].tolist())
            all_lons.extend(df['true_lon'].tolist())
            all_pred_lats.extend(df['pred_lat'].tolist())
            all_pred_lons.extend(df['pred_lon'].tolist())
        
        # Apply max_samples limit if specified
        if self.max_samples is not None:
            all_lats = all_lats[:self.max_samples]
            all_lons = all_lons[:self.max_samples]
            all_pred_lats = all_pred_lats[:self.max_samples]
            all_pred_lons = all_pred_lons[:self.max_samples]
        
        columns = ['image_bytes', 'true_lat', 'true_lon', 'pred_lat', 'pred_lon']
        if self.has_embeddings:
            columns.append('embedding')
        
        return {
            'total_samples': self.total_samples,
            'parquet_path': str(self.parquet_path),
            'parquet_files': parquet_files,
            'num_shards': len(parquet_files),
            'columns': columns,
            'has_embeddings': self.has_embeddings,
            'lat_range': (min(all_lats), max(all_lats)),
            'lon_range': (min(all_lons), max(all_lons)),
            'pred_lat_range': (min(all_pred_lats), max(all_pred_lats)),
            'pred_lon_range': (min(all_pred_lons), max(all_pred_lons))
        }
