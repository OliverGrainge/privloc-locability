#!/usr/bin/env python3
"""
Analysis script for prediction datasets generated by generate.py.

This script loads a prediction dataset and generates various statistics and visualizations:
- Recall@km for different kilometer thresholds
- Geodetic error residual distribution
- Coordinate distribution plots
- Accuracy heatmaps
- Error statistics

The script supports random subsampling of the dataset for faster analysis of large datasets.
Use --subsample N to randomly select N samples from the dataset.
"""
from dotenv import load_dotenv
load_dotenv()
import os
import sys
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Tuple
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.datasets import load_prediction_dataset
from torchvision import transforms
import torch


def haversine_distance(lat1: np.ndarray, lon1: np.ndarray, lat2: np.ndarray, lon2: np.ndarray) -> np.ndarray:
    """
    Calculate the great circle distance between two points on Earth.
    
    Args:
        lat1, lon1: First point coordinates (in degrees)
        lat2, lon2: Second point coordinates (in degrees)
    
    Returns:
        Distance in kilometers
    """
    # Convert to radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    
    # Haversine formula
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    # Earth's radius in kilometers
    r = 6371
    return c * r


def calculate_recall_at_km(true_lat: np.ndarray, true_lon: np.ndarray, 
                          pred_lat: np.ndarray, pred_lon: np.ndarray, 
                          km_thresholds: List[float]) -> dict:
    """
    Calculate recall@km for different kilometer thresholds.
    
    Args:
        true_lat, true_lon: True coordinates
        pred_lat, pred_lon: Predicted coordinates
        km_thresholds: List of kilometer thresholds to evaluate
    
    Returns:
        Dictionary with recall@km for each threshold
    """
    distances = haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
    
    recall_at_km = {}
    for km in km_thresholds:
        recall = np.mean(distances <= km)
        recall_at_km[f'recall@{km}km'] = recall
    
    return recall_at_km


def plot_recall_at_km(recall_data: dict, output_path: str):
    """Plot recall@km curve."""
    km_thresholds = [float(k.replace('recall@', '').replace('km', '')) for k in recall_data.keys()]
    recall_values = list(recall_data.values())
    
    plt.figure(figsize=(10, 6))
    plt.plot(km_thresholds, recall_values, 'b-o', linewidth=2, markersize=6)
    plt.xlabel('Distance Threshold (km)')
    plt.ylabel('Recall')
    plt.title('Recall@km Curve')
    plt.grid(True, alpha=0.3)
    plt.xlim(0, max(km_thresholds))
    plt.ylim(0, 1)
    
    # Add text annotations for key points
    for i, (km, recall) in enumerate(zip(km_thresholds, recall_values)):
        if i % 2 == 0:  # Show every other point to avoid clutter
            plt.annotate(f'{recall:.3f}', (km, recall), 
                        textcoords="offset points", xytext=(0,10), ha='center')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_error_distribution(true_lat: np.ndarray, true_lon: np.ndarray, 
                           pred_lat: np.ndarray, pred_lon: np.ndarray, 
                           output_path: str):
    """Plot geodetic error distribution."""
    distances = haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Histogram
    # Normalized histogram on left, log-normalized on right
    ax1.hist(distances, bins=50, alpha=0.7, color='skyblue', edgecolor='black', density=True)
    ax1.set_xlabel('Geodetic Error (km)')
    ax1.set_ylabel('Density')
    ax1.set_title('Distribution of Geodetic Errors (Normalized)')
    ax1.grid(True, alpha=0.3)
    
    # Add statistics
    mean_error = np.mean(distances)
    median_error = np.median(distances)
    ax1.axvline(mean_error, color='red', linestyle='--', label=f'Mean: {mean_error:.2f} km')
    ax1.axvline(median_error, color='orange', linestyle='--', label=f'Median: {median_error:.2f} km')
    ax1.legend()
    
    # Log scale histogram (also normalized)
    ax2.hist(distances, bins=50, alpha=0.7, color='lightcoral', edgecolor='black', density=True)
    ax2.set_xlabel('Geodetic Error (km)')
    ax2.set_ylabel('Density')
    ax2.set_title('Distribution of Geodetic Errors (Log Scale, Normalized)')
    ax2.set_yscale('log')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_coordinate_distributions(true_lat: np.ndarray, true_lon: np.ndarray, 
                                 pred_lat: np.ndarray, pred_lon: np.ndarray, 
                                 output_path: str):
    """Plot coordinate distributions for true vs predicted."""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # Latitude distributions
    ax1.hist(true_lat, bins=50, alpha=0.7, label='True', color='blue')
    ax1.hist(pred_lat, bins=50, alpha=0.7, label='Predicted', color='red')
    ax1.set_xlabel('Latitude')
    ax1.set_ylabel('Frequency')
    ax1.set_title('Latitude Distribution')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Longitude distributions
    ax2.hist(true_lon, bins=50, alpha=0.7, label='True', color='blue')
    ax2.hist(pred_lon, bins=50, alpha=0.7, label='Predicted', color='red')
    ax2.set_xlabel('Longitude')
    ax2.set_ylabel('Frequency')
    ax2.set_title('Longitude Distribution')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Scatter plot: True vs Predicted Latitude
    ax3.scatter(true_lat, pred_lat, alpha=0.5, s=1)
    ax3.plot([true_lat.min(), true_lat.max()], [true_lat.min(), true_lat.max()], 'r--', lw=2)
    ax3.set_xlabel('True Latitude')
    ax3.set_ylabel('Predicted Latitude')
    ax3.set_title('True vs Predicted Latitude')
    ax3.grid(True, alpha=0.3)
    
    # Scatter plot: True vs Predicted Longitude
    ax4.scatter(true_lon, pred_lon, alpha=0.5, s=1)
    ax4.plot([true_lon.min(), true_lon.max()], [true_lon.min(), true_lon.max()], 'r--', lw=2)
    ax4.set_xlabel('True Longitude')
    ax4.set_ylabel('Predicted Longitude')
    ax4.set_title('True vs Predicted Longitude')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_error_heatmap(true_lat: np.ndarray, true_lon: np.ndarray, 
                      pred_lat: np.ndarray, pred_lon: np.ndarray, 
                      output_path: str, grid_size: int = 20):
    """Plot error heatmap over geographic regions."""
    # Create grid
    lat_bins = np.linspace(true_lat.min(), true_lat.max(), grid_size)
    lon_bins = np.linspace(true_lon.min(), true_lon.max(), grid_size)
    
    # Calculate mean error for each grid cell
    error_grid = np.zeros((grid_size-1, grid_size-1))
    count_grid = np.zeros((grid_size-1, grid_size-1))
    
    for i in range(len(true_lat)):
        lat_idx = np.digitize(true_lat[i], lat_bins) - 1
        lon_idx = np.digitize(true_lon[i], lon_bins) - 1
        
        if 0 <= lat_idx < grid_size-1 and 0 <= lon_idx < grid_size-1:
            error = haversine_distance(true_lat[i], true_lon[i], pred_lat[i], pred_lon[i])
            error_grid[lat_idx, lon_idx] += error
            count_grid[lat_idx, lon_idx] += 1
    
    # Calculate mean error for each cell
    error_grid = np.divide(error_grid, count_grid, out=np.zeros_like(error_grid), where=count_grid!=0)
    
    plt.figure(figsize=(12, 8))
    im = plt.imshow(error_grid, cmap='YlOrRd', aspect='auto', 
                    extent=[lon_bins[0], lon_bins[-1], lat_bins[0], lat_bins[-1]])
    plt.colorbar(im, label='Mean Geodetic Error (km)')
    plt.xlabel('Longitude')
    plt.ylabel('Latitude')
    plt.title('Geodetic Error Heatmap')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()


def generate_summary_statistics(true_lat: np.ndarray, true_lon: np.ndarray, 
                               pred_lat: np.ndarray, pred_lon: np.ndarray) -> dict:
    """Generate comprehensive error statistics."""
    distances = haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
    
    stats = {
        'total_samples': len(true_lat),
        'mean_error_km': np.mean(distances),
        'median_error_km': np.median(distances),
        'std_error_km': np.std(distances),
        'min_error_km': np.min(distances),
        'max_error_km': np.max(distances),
        'q25_error_km': np.percentile(distances, 25),
        'q75_error_km': np.percentile(distances, 75),
        'q90_error_km': np.percentile(distances, 90),
        'q95_error_km': np.percentile(distances, 95),
        'q99_error_km': np.percentile(distances, 99),
    }
    
    # Add recall@km statistics
    km_thresholds = [1, 5, 10, 25, 50, 100, 200, 500, 1000]
    recall_stats = calculate_recall_at_km(true_lat, true_lon, pred_lat, pred_lon, km_thresholds)
    stats.update(recall_stats)
    
    return stats


def plot_best_worst_predictions(dataset, true_lat: np.ndarray, true_lon: np.ndarray, 
                               pred_lat: np.ndarray, pred_lon: np.ndarray, 
                               output_path: str, n_samples: int = 8):
    """
    Create a figure showing images with the smallest and largest prediction errors.
    
    Args:
        dataset: The prediction dataset containing images
        true_lat, true_lon: True coordinates
        pred_lat, pred_lon: Predicted coordinates  
        output_path: Path to save the figure
        n_samples: Number of samples to show for best and worst (default: 8)
    """
    # Calculate errors for all samples
    distances = haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
    
    # Get indices of best and worst predictions
    best_indices = np.argsort(distances)[:n_samples]
    worst_indices = np.argsort(distances)[-n_samples:]
    
    # Create figure with subplots
    fig, axes = plt.subplots(2, n_samples, figsize=(n_samples * 2, 6))
    if n_samples == 1:
        axes = axes.reshape(2, 1)
    
    # Set up transform to convert images back to displayable format
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    
    # Plot best predictions (top row)
    for i, idx in enumerate(best_indices):
        try:
            # Get the sample from dataset
            sample = dataset[idx]
            image = sample['image']
            
            # Convert tensor back to PIL image for display
            if isinstance(image, torch.Tensor):
                # Denormalize if needed (assuming ImageNet normalization)
                if image.min() < 0:  # Likely normalized
                    image = image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
                image = transforms.ToPILImage()(image)
            
            axes[0, i].imshow(image)
            axes[0, i].set_title(f'Error: {distances[idx]:.2f} km', fontsize=10)
            axes[0, i].axis('off')
        except Exception as e:
            axes[0, i].text(0.5, 0.5, f'Error loading\nimage {idx}', 
                           ha='center', va='center', transform=axes[0, i].transAxes)
            axes[0, i].axis('off')
    
    # Plot worst predictions (bottom row)
    for i, idx in enumerate(worst_indices):
        try:
            # Get the sample from dataset
            sample = dataset[idx]
            image = sample['image']
            
            # Convert tensor back to PIL image for display
            if isinstance(image, torch.Tensor):
                # Denormalize if needed (assuming ImageNet normalization)
                if image.min() < 0:  # Likely normalized
                    image = image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
                image = transforms.ToPILImage()(image)
            
            axes[1, i].imshow(image)
            axes[1, i].set_title(f'Error: {distances[idx]:.2f} km', fontsize=10)
            axes[1, i].axis('off')
        except Exception as e:
            axes[1, i].text(0.5, 0.5, f'Error loading\nimage {idx}', 
                           ha='center', va='center', transform=axes[1, i].transAxes)
            axes[1, i].axis('off')
    
    # Add row labels
    fig.text(0.02, 0.75, 'Best Predictions\n(Smallest Errors)', 
             rotation=90, va='center', ha='center', fontsize=12, fontweight='bold')
    fig.text(0.02, 0.25, 'Worst Predictions\n(Largest Errors)', 
             rotation=90, va='center', ha='center', fontsize=12, fontweight='bold')
    
    plt.suptitle('Image Samples: Best vs Worst Predictions', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.subplots_adjust(left=0.08)  # Make room for row labels
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()


def save_statistics(stats: dict, output_path: str):
    """Save statistics to a text file."""
    with open(output_path, 'w') as f:
        f.write("Prediction Dataset Analysis Statistics\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("Dataset Information:\n")
        f.write(f"  Total samples: {stats['total_samples']:,}\n\n")
        
        f.write("Error Statistics (km):\n")
        f.write(f"  Mean error: {stats['mean_error_km']:.2f}\n")
        f.write(f"  Median error: {stats['median_error_km']:.2f}\n")
        f.write(f"  Std deviation: {stats['std_error_km']:.2f}\n")
        f.write(f"  Min error: {stats['min_error_km']:.2f}\n")
        f.write(f"  Max error: {stats['max_error_km']:.2f}\n")
        f.write(f"  25th percentile: {stats['q25_error_km']:.2f}\n")
        f.write(f"  75th percentile: {stats['q75_error_km']:.2f}\n")
        f.write(f"  90th percentile: {stats['q90_error_km']:.2f}\n")
        f.write(f"  95th percentile: {stats['q95_error_km']:.2f}\n")
        f.write(f"  99th percentile: {stats['q99_error_km']:.2f}\n\n")
        
        f.write("Recall@km Statistics:\n")
        for key, value in stats.items():
            if key.startswith('recall@'):
                f.write(f"  {key}: {value:.3f}\n")


def main():
    parser = argparse.ArgumentParser(description='Analyze prediction dataset')
    parser.add_argument('dataset_name', help='Name of the dataset (e.g., yfcc100m)')
    parser.add_argument('model_name', help='Name of the model (e.g., geoclip)')
    parser.add_argument('--output_dir', default='predictions', help='Directory containing prediction files')
    parser.add_argument('--max_samples', type=int, help='Maximum number of samples to analyze (for debugging)')
    parser.add_argument('--subsample', type=int, help='Number of samples to randomly subsample from the dataset')
    parser.add_argument('--random_seed', type=int, default=42, help='Random seed for reproducible subsampling (default: 42)')
    parser.add_argument('--plots_dir', default='plots', help='Directory to save plots')
    parser.add_argument('--n_best_worst', type=int, default=8, help='Number of best and worst samples to show in visualization (default: 8)')
    
    args = parser.parse_args()
    
    # Create output directory structure
    plots_dir = Path(args.plots_dir) / args.dataset_name / args.model_name
    plots_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"Loading prediction dataset: {args.dataset_name} - {args.model_name}")
    print(f"Plots will be saved to: {plots_dir}")
    
    # Load dataset
    try:
        dataset = load_prediction_dataset(
            dataset_name=args.dataset_name,
            model_name=args.model_name,
            max_samples=args.max_samples
        )
        print(f"Loaded {len(dataset)} samples")
    except Exception as e:
        print(f"Error loading dataset: {e}")
        return
    
    # Apply subsampling if requested
    if args.subsample is not None:
        if args.subsample > len(dataset):
            print(f"Warning: Requested subsample size ({args.subsample}) is larger than dataset size ({len(dataset)}). Using full dataset.")
        else:
            print(f"Will subsample first {args.subsample} samples sequentially from files")
            # We'll handle subsampling during coordinate extraction to keep it sequential
    
    # Extract coordinates using sequential file access for efficiency
    print("Extracting coordinates...")
    true_lats = []
    true_lons = []
    pred_lats = []
    pred_lons = []
    
    # Use sequential file access to avoid random file loading
    if hasattr(dataset, 'get_file_samples'):
        # Use the new efficient method with sequential subsampling
        total_processed = 0
        target_samples = args.subsample if args.subsample is not None else len(dataset)
        
        for file_idx in range(len(dataset.parquet_files)):
            if total_processed >= target_samples:
                break
                
            
            samples = dataset.get_file_samples(file_idx)
            
            for sample in samples:
                if total_processed >= target_samples:
                    break
                if total_processed % 1000 == 0:
                    print(f"Processing Dataset {total_processed/target_samples*100:.2f}%")
                true_lats.append(sample['true_lat'].item())
                true_lons.append(sample['true_lon'].item())
                pred_lats.append(sample['pred_lat'].item())
                pred_lons.append(sample['pred_lon'].item())
                total_processed += 1
                
        print(f"Sequentially processed {total_processed} samples from {file_idx + 1} files")
    else:
        # Fallback to original method
        target_samples = args.subsample if args.subsample is not None else len(dataset)
        for i in range(min(len(dataset), target_samples)):
            sample = dataset[i]
            true_lats.append(sample['true_lat'].item())
            true_lons.append(sample['true_lon'].item())
            pred_lats.append(sample['pred_lat'].item())
            pred_lons.append(sample['pred_lon'].item())
            
            if (i + 1) % 1000 == 0:
                print(f"Processed {i + 1}/{target_samples} samples ({i + 1 / target_samples * 100:.2f}%)")
    
    true_lat = np.array(true_lats)
    true_lon = np.array(true_lons)
    pred_lat = np.array(pred_lats)
    pred_lon = np.array(pred_lons)
    
    print("Generating statistics...")
    stats = generate_summary_statistics(true_lat, true_lon, pred_lat, pred_lon)
    
    # Save statistics
    stats_file = plots_dir / 'statistics.txt'
    save_statistics(stats, stats_file)
    print(f"Statistics saved to: {stats_file}")
    
    # Generate plots
    print("Generating plots...")
    
    # Recall@km plot
    km_thresholds = [1, 5, 10, 25, 50, 100, 200, 500, 1000, 2000, 5000]
    recall_data = calculate_recall_at_km(true_lat, true_lon, pred_lat, pred_lon, km_thresholds)
    plot_recall_at_km(recall_data, plots_dir / 'recall_at_km.png')
    print("✓ Recall@km plot saved")
    
    # Error distribution plot
    plot_error_distribution(true_lat, true_lon, pred_lat, pred_lon, plots_dir / 'error_distribution.png')
    print("✓ Error distribution plot saved")
    
    # Coordinate distributions
    plot_coordinate_distributions(true_lat, true_lon, pred_lat, pred_lon, plots_dir / 'coordinate_distributions.png')
    print("✓ Coordinate distribution plots saved")
    
    # Error heatmap
    plot_error_heatmap(true_lat, true_lon, pred_lat, pred_lon, plots_dir / 'error_heatmap.png')
    print("✓ Error heatmap saved")
    
    # Best and worst predictions visualization
    plot_best_worst_predictions(dataset, true_lat, true_lon, pred_lat, pred_lon, plots_dir / 'best_worst_predictions.png', n_samples=args.n_best_worst)
    print("✓ Best/worst predictions visualization saved")
    
    print(f"\nAnalysis complete! All plots saved to: {plots_dir}")
    print(f"Key statistics:")
    print(f"  Mean error: {stats['mean_error_km']:.2f} km")
    print(f"  Median error: {stats['median_error_km']:.2f} km")
    print(f"  Recall@1km: {stats['recall@1km']:.3f}")
    print(f"  Recall@10km: {stats['recall@10km']:.3f}")
    print(f"  Recall@100km: {stats['recall@100km']:.3f}")


if __name__ == "__main__":
    main()
