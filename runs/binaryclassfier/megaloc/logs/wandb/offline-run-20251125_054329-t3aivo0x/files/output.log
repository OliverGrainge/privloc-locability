LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name       | Type              | Params | Mode
---------------------------------------------------------
0 | model      | MegaLoc           | 228 M  | train
1 | bce_loss   | BCEWithLogitsLoss | 0      | train
2 | val_auroc  | BinaryAUROC       | 0      | train
3 | test_auroc | BinaryAUROC       | 0      | train
4 | val_roc    | BinaryROC         | 0      | train
5 | test_roc   | BinaryROC         | 0      | train
---------------------------------------------------------
185 M     Trainable params
43.0 M    Non-trainable params
228 M     Total params
914.595   Total estimated model params size (MB)
224       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/home/oeg1n18/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/home/oeg1n18/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/home/oeg1n18/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Epoch 0, global step 500: 'val/loss' reached 0.47588 (best 0.47588), saving model to '/iridisfs/home/oeg1n18/privloc-locability/runs/binaryclassfier/megaloc/checkpoints/best_model.ckpt' as top 1
Sanity Checking: |                                                               | 0/? [00:00<?, ?it/s]Loading Shard 1/11: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_010.parquet
Prefetching Shard 2/11: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_011.parquet
Epoch 0:   0%|                                                               | 0/15625 [00:00<?, ?it/s]Loading Shard 1/10: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_000.parquet
Prefetching Shard 2/10: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_001.parquet
Epoch 0:   7%| | 1132/15625 [17:27<3:43:33,  1.08it/s, v_num=vo0x, train/loss=0.551, val/loss=0.505, va
Epoch 0, global step 1000: 'val/loss' was not in top 1
Epoch 0:  10%| | 1562/15625 [24:29<3:40:28,  1.06it/s, v_num=vo0x, train/loss=0.503, val/loss=0.480, vaUsing prefetched Shard 2/10: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_001.parquet
Prefetching Shard 3/10: /iridisfs/geosets/oeg1n18/predictiondatasets/predictions/mp16_geoclip/part_002.parquet
Epoch 0:  13%|â–| 2000/15625 [31:32<3:34:52,  1.06it/s, v_num=vo0x, train/loss=0.519, val/loss=0.476, va
Training completed successfully!
Best model saved at: /iridisfs/home/oeg1n18/privloc-locability/runs/binaryclassfier/megaloc/checkpoints/best_model.ckpt
Training completed! Use test.py to run evaluation on test datasets.
Epoch 0, global step 2000: 'val/loss' was not in top 1
`Trainer.fit` stopped: `max_steps=2000` reached.